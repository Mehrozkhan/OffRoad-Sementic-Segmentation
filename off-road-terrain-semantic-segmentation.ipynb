{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport os\n\n\nimport torch \nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision\nfrom torchvision import transforms \n\n# Image processing lib\nimport albumentations as album\nimport cv2\nfrom PIL import Image\n\nfrom tqdm.notebook import tqdm\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n!pip install -q segmentation-models-pytorch\nimport segmentation_models_pytorch as smp\n\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-25T18:30:14.099396Z","iopub.execute_input":"2021-09-25T18:30:14.099958Z","iopub.status.idle":"2021-09-25T18:30:34.424090Z","shell.execute_reply.started":"2021-09-25T18:30:14.099879Z","shell.execute_reply":"2021-09-25T18:30:34.423261Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2021-09-25T18:30:38.576108Z","iopub.execute_input":"2021-09-25T18:30:38.576814Z","iopub.status.idle":"2021-09-25T18:30:38.580269Z","shell.execute_reply.started":"2021-09-25T18:30:38.576780Z","shell.execute_reply":"2021-09-25T18:30:38.579605Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #device on which data will be trained","metadata":{"execution":{"iopub.status.busy":"2021-09-25T18:30:39.336397Z","iopub.execute_input":"2021-09-25T18:30:39.337073Z","iopub.status.idle":"2021-09-25T18:30:39.386125Z","shell.execute_reply.started":"2021-09-25T18:30:39.337037Z","shell.execute_reply":"2021-09-25T18:30:39.385360Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"images_path = '../input/offroad-terrain-attention-region-images/TrainingImages/TrainingImages/OriginalImages'\nmask_path_1 = '../input/offroad-terrain-attention-region-images/TrainingImages/TrainingImages/EnumMasks/png_0_1'\nmask_path_2 = '../input/offroad-terrain-attention-region-images/TrainingImages/TrainingImages/EnumMasks/png_0_255'","metadata":{"execution":{"iopub.status.busy":"2021-09-25T18:30:40.248685Z","iopub.execute_input":"2021-09-25T18:30:40.248938Z","iopub.status.idle":"2021-09-25T18:30:40.252697Z","shell.execute_reply.started":"2021-09-25T18:30:40.248912Z","shell.execute_reply":"2021-09-25T18:30:40.252033Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\ndef dataset_ser(path):\n    images_list = []\n    for dirname, _, filenames in os.walk(path):\n        for filename in filenames:\n            images_list.append(filename)\n    images_list.sort()\n    return pd.Series(images_list)\n\nimage_df = dataset_ser(images_path) \nmask_df_1  = dataset_ser(mask_path_1)\nmask_df_2 = dataset_ser(mask_path_2)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T18:30:40.929524Z","iopub.execute_input":"2021-09-25T18:30:40.930059Z","iopub.status.idle":"2021-09-25T18:30:41.451898Z","shell.execute_reply.started":"2021-09-25T18:30:40.930022Z","shell.execute_reply":"2021-09-25T18:30:41.451118Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#sample image with mask applied\n\nimg = Image.open(os.path.join(images_path, image_df[0]))\nmsk = Image.open(os.path.join(mask_path_1, mask_df_1[0]))\n\nplt.imshow(img)\nplt.imshow(msk, alpha = 0.3)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T18:30:41.454129Z","iopub.execute_input":"2021-09-25T18:30:41.454366Z","iopub.status.idle":"2021-09-25T18:30:44.302012Z","shell.execute_reply.started":"2021-09-25T18:30:41.454339Z","shell.execute_reply":"2021-09-25T18:30:44.301174Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"print('Number of images : ', len(image_df))\nprint('Number of masks_1 : ', len(mask_df_1))\nprint('Number of masks_2 : ', len(mask_df_2))\nprint('size of image : ', np.array(Image.open(os.path.join(images_path, image_df[0]))).shape)\nprint('size of masks : ', np.array(Image.open(os.path.join(mask_path_1, mask_df_1[0]))).shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T18:30:44.303401Z","iopub.execute_input":"2021-09-25T18:30:44.304297Z","iopub.status.idle":"2021-09-25T18:30:44.499427Z","shell.execute_reply.started":"2021-09-25T18:30:44.304255Z","shell.execute_reply":"2021-09-25T18:30:44.498627Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def visualize_masks(**images):\n    \"\"\"\n    To visulize multiple images simultaneously\n    \n    input : images is **kwargs, just like dict\n    More abour kwargs : https://realpython.com/python-kwargs-and-args/\n    \n    \n    \"\"\"\n    plt.figure(figsize = (30,10)) #setting image size\n    for id, (name , image) in enumerate(images.items()):\n        \n        plt.subplot(1, len(images), id+1) # creating subplots\n        plt.title(name) # naming subplots\n        plt.imshow(image)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T18:30:44.500634Z","iopub.execute_input":"2021-09-25T18:30:44.501375Z","iopub.status.idle":"2021-09-25T18:30:44.507581Z","shell.execute_reply.started":"2021-09-25T18:30:44.501335Z","shell.execute_reply":"2021-09-25T18:30:44.506769Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def img_to_nparray(img):\n    \n    \"\"\"\n    covert image read by PIL.Image to numpy array\n    \n    \"\"\"\n    \n    return np.array(img)\n\ndef read_image(i):\n    \n    \"\"\"\n    input : i , int, index of image or mask  to visualize\n    \n    \"\"\"\n    \n    img = img_to_nparray(Image.open(os.path.join(images_path, image_df[i])))\n    mask_1 = img_to_nparray(Image.open(os.path.join(mask_path_1, mask_df_1[i])))\n    mask_2 = img_to_nparray(Image.open(os.path.join(mask_path_2, mask_df_2[i])))\n    \n    \n    return img, mask_1, mask_2\n    \n","metadata":{"execution":{"iopub.status.busy":"2021-09-25T18:30:44.509427Z","iopub.execute_input":"2021-09-25T18:30:44.509706Z","iopub.status.idle":"2021-09-25T18:30:44.519133Z","shell.execute_reply.started":"2021-09-25T18:30:44.509666Z","shell.execute_reply":"2021-09-25T18:30:44.518270Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"img, mask_1, mask_2 = read_image(6)\n\nvisualize_masks(Image = img , \n               Mask_1 = mask_1,\n               Mask_2 = mask_2)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T18:30:44.520370Z","iopub.execute_input":"2021-09-25T18:30:44.521188Z","iopub.status.idle":"2021-09-25T18:30:48.769813Z","shell.execute_reply.started":"2021-09-25T18:30:44.521148Z","shell.execute_reply":"2021-09-25T18:30:48.763282Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"There is  visually no difference. Only difference is values of pixels i.e. 1 or 255. So we will \ncontinue only with mask_1","metadata":{}},{"cell_type":"code","source":"dummy_images, test_images, dummy_masks,test_masks  = train_test_split(image_df, mask_df_1 , test_size = 0.2 , shuffle = True)\ntrain_images, val_images, train_masks, val_masks  = train_test_split(dummy_images,dummy_masks , test_size = 0.2 , shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T18:30:48.772053Z","iopub.execute_input":"2021-09-25T18:30:48.772387Z","iopub.status.idle":"2021-09-25T18:30:48.780648Z","shell.execute_reply.started":"2021-09-25T18:30:48.772346Z","shell.execute_reply":"2021-09-25T18:30:48.779870Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"print('Train Images   : ', len(train_images))\nprint('Val Images     : ', len(val_images))\nprint('Test Images    : ', len(test_images))","metadata":{"execution":{"iopub.status.busy":"2021-09-25T18:30:48.781696Z","iopub.execute_input":"2021-09-25T18:30:48.782475Z","iopub.status.idle":"2021-09-25T18:30:48.792552Z","shell.execute_reply.started":"2021-09-25T18:30:48.782436Z","shell.execute_reply":"2021-09-25T18:30:48.791749Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class OffRoadData(Dataset):\n    \n    def __init__(self,\n                 image_path,mask_path,\n                 images, masks,\n                 transform = None):\n    \n        self.image_path = image_path\n        self.mask_path  = mask_path\n        self.images     = images\n        self.masks      = masks\n        self.transform  = transform\n\n    def __len__(self):\n        return len(self.images)\n    \n    def __getitem__(self, i):\n        \n        img = cv2.cvtColor(cv2.imread(os.path.join(self.image_path , self.images.iloc[i])), cv2.COLOR_BGR2RGB)\n        msk = cv2.imread(os.path.join(self.mask_path , self.masks.iloc[i]), cv2.IMREAD_GRAYSCALE)\n        \n        if self.transform is not None:\n            aug = self.transform( image = img, mask = msk)\n            img = aug['image']\n            msk = aug['mask']\n           \n        tensor_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n        img = tensor_transform(img)\n        msk = torch.from_numpy(msk).long()\n        \n        \n        return img,msk\n             ","metadata":{"execution":{"iopub.status.busy":"2021-09-25T18:30:48.794157Z","iopub.execute_input":"2021-09-25T18:30:48.794469Z","iopub.status.idle":"2021-09-25T18:30:48.804771Z","shell.execute_reply.started":"2021-09-25T18:30:48.794434Z","shell.execute_reply":"2021-09-25T18:30:48.803658Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_transforms = album.Compose([\n    album.Resize(704, 960, interpolation = cv2.INTER_NEAREST),\n    album.OneOf([album.HorizontalFlip(p=1), album.VerticalFlip(p=1)],p=0.75),\n    album.RandomBrightnessContrast((0.1, 0.4), (0.1,0.4), p = 0.9),\n    album.GridDistortion(p = 0.2), \n    \n])\n\nval_transforms = album.Compose([\n    album.Resize(704, 960, interpolation = cv2.INTER_NEAREST),\n    album.OneOf([album.HorizontalFlip(p=1), album.VerticalFlip(p=1)],p=0.9),\n    \n])","metadata":{"execution":{"iopub.status.busy":"2021-09-25T18:30:48.806069Z","iopub.execute_input":"2021-09-25T18:30:48.806547Z","iopub.status.idle":"2021-09-25T18:30:48.817583Z","shell.execute_reply.started":"2021-09-25T18:30:48.806510Z","shell.execute_reply":"2021-09-25T18:30:48.816794Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train_data = OffRoadData(images_path, mask_path_1, train_images, train_masks, train_transforms)\nval_data   = OffRoadData(images_path, mask_path_1, val_images, val_masks, val_transforms)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T18:30:48.819753Z","iopub.execute_input":"2021-09-25T18:30:48.820027Z","iopub.status.idle":"2021-09-25T18:30:48.826607Z","shell.execute_reply.started":"2021-09-25T18:30:48.819992Z","shell.execute_reply":"2021-09-25T18:30:48.825866Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"batch_size= 3\n\ntrain_loader = DataLoader(train_data, batch_size= batch_size, shuffle=True)\nval_loader = DataLoader(val_data, batch_size= batch_size , shuffle= True)  ","metadata":{"execution":{"iopub.status.busy":"2021-09-25T18:30:48.827904Z","iopub.execute_input":"2021-09-25T18:30:48.828159Z","iopub.status.idle":"2021-09-25T18:30:48.835034Z","shell.execute_reply.started":"2021-09-25T18:30:48.828126Z","shell.execute_reply":"2021-09-25T18:30:48.834385Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"model = smp.Unet(encoder_name= 'resnet34', encoder_weights= 'imagenet', classes= 2, activation= None ,encoder_depth=5, decoder_channels=[256, 128, 64, 32,16])","metadata":{"execution":{"iopub.status.busy":"2021-09-25T18:30:48.836400Z","iopub.execute_input":"2021-09-25T18:30:48.836731Z","iopub.status.idle":"2021-09-25T18:30:53.462249Z","shell.execute_reply.started":"2021-09-25T18:30:48.836689Z","shell.execute_reply":"2021-09-25T18:30:53.461507Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model.to(device) #moving model to the cuda","metadata":{"execution":{"iopub.status.busy":"2021-09-25T18:31:01.309598Z","iopub.execute_input":"2021-09-25T18:31:01.310257Z","iopub.status.idle":"2021-09-25T18:31:06.774766Z","shell.execute_reply.started":"2021-09-25T18:31:01.310213Z","shell.execute_reply":"2021-09-25T18:31:06.774065Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"#number of epochs\nn_epochs = 12\n\n#optimizer \noptimizer = torch.optim.Adam(params= model.parameters(), lr = 1e-5, weight_decay= 1e-4)\n\nloss_fn = nn.CrossEntropyLoss()\n\nsched = torch.optim.lr_scheduler.OneCycleLR(optimizer,max_lr= 1e-5, epochs= n_epochs,steps_per_epoch= len(train_loader))\n","metadata":{"execution":{"iopub.status.busy":"2021-09-25T18:31:36.455332Z","iopub.execute_input":"2021-09-25T18:31:36.456020Z","iopub.status.idle":"2021-09-25T18:31:36.463550Z","shell.execute_reply.started":"2021-09-25T18:31:36.455985Z","shell.execute_reply":"2021-09-25T18:31:36.462764Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"#inspired by another notebook(https://www.kaggle.com/ligtfeather/semantic-segmentation-is-easy-with-pytorch)\ndef mIoU(pred_mask, mask, smooth=1e-10, n_classes=2):\n    with torch.no_grad():\n        pred_mask = F.softmax(pred_mask, dim=1)\n        pred_mask = torch.argmax(pred_mask, dim=1)\n        pred_mask = pred_mask.contiguous().view(-1)\n        mask = mask.contiguous().view(-1)\n\n        iou_per_class = []\n        for clas in range(0, n_classes): #loop per pixel class\n            true_class = pred_mask == clas\n            true_label = mask == clas\n\n            if true_label.long().sum().item() == 0: #no exist label in this loop\n                iou_per_class.append(np.nan)\n            else:\n                intersect = torch.logical_and(true_class, true_label).sum().float().item()\n                union = torch.logical_or(true_class, true_label).sum().float().item()\n\n                iou = (intersect + smooth) / (union +smooth)\n                iou_per_class.append(iou)\n        return np.nanmean(iou_per_class)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T18:32:45.157837Z","iopub.execute_input":"2021-09-25T18:32:45.158106Z","iopub.status.idle":"2021-09-25T18:32:45.165965Z","shell.execute_reply.started":"2021-09-25T18:32:45.158078Z","shell.execute_reply":"2021-09-25T18:32:45.165303Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def train_loop(model, train_loader, val_loader, loss_fn, optimizer, scheduler, n_epochs):\n    \n    torch.cuda.empty_cache()\n    per_epoch_train_loss = []; per_epoch_val_loss = [];\n    per_epoch_train_iou = []; per_epoch_val_iou = [];\n    \n    for epoch in range(n_epochs):\n        \n        model.train()\n        train_loss = 0\n        train_iou = 0\n        \n        \n        for i, (images, masks) in enumerate(tqdm(train_loader)):\n            \n            image = images.to(device) ; mask = masks.squeeze().to(device)\n            \n            output = model(image)\n            \n            loss = loss_fn(output, mask)\n            train_iou += mIoU(output, mask)\n            \n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n            \n            scheduler.step()\n            \n            train_loss += loss.item()\n        \n        per_epoch_train_loss.append(train_loss/len(train_loader))\n        per_epoch_train_iou.append(train_iou/len(train_loader))    \n        \n        model.eval()\n        with torch.no_grad():\n            val_loss = 0\n            val_iou =  0\n\n\n\n            for i, (images, masks) in enumerate(tqdm(val_loader)):\n\n                image = images.to(device) ; mask = masks.squeeze().to(device)\n\n                output = model(image)\n\n                loss = loss_fn(output, mask)\n                val_iou += mIoU(output, mask)\n                val_loss += loss.item()\n        \n        per_epoch_val_loss.append(val_loss/len(val_loader))\n        per_epoch_val_iou.append(val_iou/len(val_loader))\n        \n        print(\"Epoch:{}/{}..\".format(epoch+1, n_epochs),\n                  \"Train Loss: {:.3f}..\".format(train_loss/len(train_loader)),\n                  \"Val Loss: {:.3f}..\".format(val_loss/len(val_loader)),\n                  \"Train mIoU:{:.3f}..\".format(train_iou/len(train_loader)),\n                  \"Val mIoU: {:.3f}..\".format(val_iou/len(val_loader)),\n                  )\n        \n    history = {'train_loss' : per_epoch_train_loss, 'val_loss': per_epoch_val_loss,\n               'train_miou' : per_epoch_train_iou, 'val_miou': per_epoch_val_iou\n               }\n    \n    \n    return history","metadata":{"execution":{"iopub.status.busy":"2021-09-25T18:32:46.185823Z","iopub.execute_input":"2021-09-25T18:32:46.186259Z","iopub.status.idle":"2021-09-25T18:32:46.199125Z","shell.execute_reply.started":"2021-09-25T18:32:46.186225Z","shell.execute_reply":"2021-09-25T18:32:46.198119Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"A lot of the time was utilized to find an optimum values of hyperparameters.","metadata":{}},{"cell_type":"code","source":"a = train_loop(model,train_loader,val_loader ,loss_fn, optimizer, sched, n_epochs)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T18:32:56.715659Z","iopub.execute_input":"2021-09-25T18:32:56.715925Z","iopub.status.idle":"2021-09-25T18:53:01.218026Z","shell.execute_reply.started":"2021-09-25T18:32:56.715896Z","shell.execute_reply":"2021-09-25T18:53:01.217318Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"torch.save(model, 'Model_1.pt')","metadata":{"execution":{"iopub.status.busy":"2021-09-25T18:53:42.500656Z","iopub.execute_input":"2021-09-25T18:53:42.500931Z","iopub.status.idle":"2021-09-25T18:53:42.691914Z","shell.execute_reply.started":"2021-09-25T18:53:42.500902Z","shell.execute_reply":"2021-09-25T18:53:42.691173Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def plot(history, val_1, val_2, title, x_label, y_label):\n    \n    plt.plot(history[val_1],label = 'train', marker='o')\n    plt.plot( history[val_2], label='val', marker='*')\n    plt.title(title); plt.ylabel(y_label);\n    plt.xlabel(x_label)\n    plt.legend()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-25T18:53:45.740750Z","iopub.execute_input":"2021-09-25T18:53:45.741005Z","iopub.status.idle":"2021-09-25T18:53:45.746199Z","shell.execute_reply.started":"2021-09-25T18:53:45.740979Z","shell.execute_reply":"2021-09-25T18:53:45.745300Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def plot_loss_metrics(history, loss = False , mIoU = False):\n    \n    if loss:\n        val_1 = list(history.keys())[0]\n        val_2 = list(history.keys())[1]\n        title = 'Loss per epoch'\n        x_label = 'epoch'\n        y_label = 'loss'\n        plot(history, val_1,val_2,title, x_label, y_label)\n        \n    if mIoU:\n        val_1 = list(history.keys())[2]\n        val_2 = list(history.keys())[3]\n        title = 'Mean IoU'\n        x_label = 'epoch'\n        y_label = 'mIoU'\n        plot(history,val_1,val_2,title, x_label, y_label)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T18:53:46.669083Z","iopub.execute_input":"2021-09-25T18:53:46.669624Z","iopub.status.idle":"2021-09-25T18:53:46.676060Z","shell.execute_reply.started":"2021-09-25T18:53:46.669588Z","shell.execute_reply":"2021-09-25T18:53:46.675263Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"plot_loss_metrics(history= a, loss = True,mIoU = True)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T18:53:48.115090Z","iopub.execute_input":"2021-09-25T18:53:48.115649Z","iopub.status.idle":"2021-09-25T18:53:48.498342Z","shell.execute_reply.started":"2021-09-25T18:53:48.115614Z","shell.execute_reply":"2021-09-25T18:53:48.497706Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"test_transforms = album.Compose([album.Resize(704, 960, interpolation = cv2.INTER_NEAREST)])","metadata":{"execution":{"iopub.status.busy":"2021-09-25T18:54:01.112596Z","iopub.execute_input":"2021-09-25T18:54:01.112895Z","iopub.status.idle":"2021-09-25T18:54:01.118572Z","shell.execute_reply.started":"2021-09-25T18:54:01.112865Z","shell.execute_reply":"2021-09-25T18:54:01.117114Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"test_data   = OffRoadData(images_path, mask_path_1, test_images, test_masks, test_transforms)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T18:54:10.659522Z","iopub.execute_input":"2021-09-25T18:54:10.659774Z","iopub.status.idle":"2021-09-25T18:54:10.663333Z","shell.execute_reply.started":"2021-09-25T18:54:10.659747Z","shell.execute_reply":"2021-09-25T18:54:10.662648Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def predict_image_mask_miou(model, image, mask):\n    model.eval()\n    \n    model.to(device); image=image.to(device)\n    mask = mask.to(device)\n    with torch.no_grad():\n        \n       \n        image = image.unsqueeze(0)\n        mask = mask.unsqueeze(0)\n        output = model(image)\n        \n        score = mIoU(output, mask)\n        \n        masked = torch.argmax(output, dim=1)\n        masked = masked.cpu().squeeze(0)\n        \n    return masked, score","metadata":{"execution":{"iopub.status.busy":"2021-09-25T18:54:12.338879Z","iopub.execute_input":"2021-09-25T18:54:12.339410Z","iopub.status.idle":"2021-09-25T18:54:12.345414Z","shell.execute_reply.started":"2021-09-25T18:54:12.339376Z","shell.execute_reply":"2021-09-25T18:54:12.344751Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"image , mask = test_data[100]","metadata":{"execution":{"iopub.status.busy":"2021-09-25T18:58:18.471685Z","iopub.execute_input":"2021-09-25T18:58:18.471946Z","iopub.status.idle":"2021-09-25T18:58:18.623528Z","shell.execute_reply.started":"2021-09-25T18:58:18.471917Z","shell.execute_reply":"2021-09-25T18:58:18.622795Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"pred_mask, score = predict_image_mask_miou(model, image, mask)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T18:58:19.498588Z","iopub.execute_input":"2021-09-25T18:58:19.499271Z","iopub.status.idle":"2021-09-25T18:58:19.543501Z","shell.execute_reply.started":"2021-09-25T18:58:19.499236Z","shell.execute_reply":"2021-09-25T18:58:19.542703Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"visualize_masks(original_mask = mask, predicted_mask = pred_mask)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T18:58:20.481486Z","iopub.execute_input":"2021-09-25T18:58:20.482153Z","iopub.status.idle":"2021-09-25T18:58:21.097855Z","shell.execute_reply.started":"2021-09-25T18:58:20.482117Z","shell.execute_reply":"2021-09-25T18:58:21.097131Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"def miou_score(model, test_set):\n    score_iou = []\n    for i in tqdm(range(len(test_set))):\n        img, mask = test_set[i]\n        pred_mask, score = predict_image_mask_miou(model, img, mask)\n        score_iou.append(score)\n    return score_iou","metadata":{"execution":{"iopub.status.busy":"2021-09-25T18:54:58.246994Z","iopub.execute_input":"2021-09-25T18:54:58.247684Z","iopub.status.idle":"2021-09-25T18:54:58.254802Z","shell.execute_reply.started":"2021-09-25T18:54:58.247648Z","shell.execute_reply":"2021-09-25T18:54:58.253986Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"mob_miou = miou_score(model, test_data)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T18:55:23.362065Z","iopub.execute_input":"2021-09-25T18:55:23.362388Z","iopub.status.idle":"2021-09-25T18:55:43.626944Z","shell.execute_reply.started":"2021-09-25T18:55:23.362349Z","shell.execute_reply":"2021-09-25T18:55:43.626281Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"print('Test Set mIoU', np.mean(mob_miou))","metadata":{"execution":{"iopub.status.busy":"2021-09-25T18:55:58.973713Z","iopub.execute_input":"2021-09-25T18:55:58.973976Z","iopub.status.idle":"2021-09-25T18:55:58.979357Z","shell.execute_reply.started":"2021-09-25T18:55:58.973947Z","shell.execute_reply":"2021-09-25T18:55:58.978339Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}